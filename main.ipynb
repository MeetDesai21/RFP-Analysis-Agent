{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeetDesai21/RFP-Analysis-Agent/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ANQkR8zJ2-1u",
        "outputId": "ca3fa53f-aed8-4a78-fd26-ed8a3f0160a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Waiting for headers] [1 I\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Waiting for headers] [Con\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,729 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,944 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,540 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,387 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,969 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,255 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,552 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.6 kB]\n",
            "Get:23 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.1 kB]\n",
            "Fetched 32.0 MB in 3s (9,923 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pytesseract, pyngrok, PyMuPDF, pdf2image, pydeck, streamlit\n",
            "Successfully installed PyMuPDF-1.26.0 pdf2image-1.17.0 pydeck-0.9.1 pyngrok-7.2.8 pytesseract-0.3.13 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install streamlit google-generativeai pytesseract pillow pdf2image PyMuPDF pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTL2_9Gu3LJQ",
        "outputId": "59f15309-4cba-4e87-a00a-e2cf09cf744e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your ngrok auth token: ··········\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "# Get your ngrok auth token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok_token = getpass.getpass(\"Enter your ngrok auth token: \")\n",
        "ngrok.set_auth_token(ngrok_token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eUC6wfL2bEB",
        "outputId": "c2f8f648-b7e5-40ea-e5b9-ef8019c7c517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing rfp_analyzer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile rfp_analyzer.py\n",
        "import streamlit as st\n",
        "import json\n",
        "import tempfile\n",
        "import os\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import pdf2image\n",
        "import fitz  # PyMuPDF\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from docx.shared import RGBColor\n",
        "from io import BytesIO\n",
        "\n",
        "class RFPAnalyzer:\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"Initialize the RFP Analyzer with Gemini API key\"\"\"\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "        self.generation_config = genai.types.GenerationConfig(\n",
        "            temperature=0.1,\n",
        "            max_output_tokens=8192,\n",
        "        )\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file) -> str:\n",
        "        \"\"\"Extract text from PDF using PyMuPDF first, fallback to OCR\"\"\"\n",
        "        try:\n",
        "            # Save uploaded file temporarily\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
        "                tmp_file.write(pdf_file.read())\n",
        "                tmp_path = tmp_file.name\n",
        "\n",
        "            # Try direct text extraction first\n",
        "            doc = fitz.open(tmp_path)\n",
        "            text = \"\"\n",
        "\n",
        "            for page_num in range(doc.page_count):\n",
        "                page = doc[page_num]\n",
        "                page_text = page.get_text()\n",
        "\n",
        "                # If page has little text, use OCR\n",
        "                if len(page_text.strip()) < 100:\n",
        "                    # Convert page to image and OCR\n",
        "                    pix = page.get_pixmap()\n",
        "                    img_data = pix.tobytes(\"png\")\n",
        "\n",
        "                    # Save as temporary image\n",
        "                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as img_file:\n",
        "                        img_file.write(img_data)\n",
        "                        img_path = img_file.name\n",
        "\n",
        "                    # OCR the image\n",
        "                    ocr_text = pytesseract.image_to_string(Image.open(img_path))\n",
        "                    text += f\"\\n--- Page {page_num + 1} (OCR) ---\\n{ocr_text}\\n\"\n",
        "\n",
        "                    # Clean up\n",
        "                    os.unlink(img_path)\n",
        "                else:\n",
        "                    text += f\"\\n--- Page {page_num + 1} ---\\n{page_text}\\n\"\n",
        "\n",
        "            doc.close()\n",
        "            os.unlink(tmp_path)\n",
        "\n",
        "            return text\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error extracting text from PDF: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def extract_text_from_image(self, image_file) -> str:\n",
        "        \"\"\"Extract text from image using OCR\"\"\"\n",
        "        try:\n",
        "            image = Image.open(image_file)\n",
        "            text = pytesseract.image_to_string(image)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error extracting text from image: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def analyze_rfp(self, text: str) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze RFP text and extract structured information\"\"\"\n",
        "\n",
        "        analysis_prompt = f\"\"\"You are an expert RFP analyst for contractor companies.\n",
        "Analyze the provided RFP document and extract comprehensive insights in a structured JSON format.\n",
        "Focus on information that helps contractors understand requirements and prepare competitive bids.\n",
        "\n",
        "Analyze this RFP document and provide detailed insights in the following JSON structure:\n",
        "\n",
        "{{\n",
        "    \"project_overview\": {{\n",
        "        \"title\": \"Project title\",\n",
        "        \"description\": \"Brief project description\",\n",
        "        \"client_organization\": \"Client name/organization\",\n",
        "        \"project_type\": \"Type of project\",\n",
        "        \"industry_sector\": \"Industry/sector\"\n",
        "    }},\n",
        "    \"requirements\": {{\n",
        "        \"functional_requirements\": [\"List of functional requirements\"],\n",
        "        \"technical_requirements\": [\"List of technical requirements\"],\n",
        "        \"compliance_requirements\": [\"Regulatory/compliance needs\"],\n",
        "        \"performance_requirements\": [\"Performance criteria\"]\n",
        "    }},\n",
        "    \"technology_stack\": {{\n",
        "        \"preferred_technologies\": [\"Preferred tech stack\"],\n",
        "        \"platforms\": [\"Required platforms\"],\n",
        "        \"databases\": [\"Database requirements\"],\n",
        "        \"frameworks\": [\"Framework preferences\"],\n",
        "        \"third_party_integrations\": [\"Required integrations\"]\n",
        "    }},\n",
        "    \"project_details\": {{\n",
        "        \"estimated_budget\": \"Budget range if mentioned\",\n",
        "        \"timeline\": \"Project timeline\",\n",
        "        \"start_date\": \"Expected start date\",\n",
        "        \"key_milestones\": [\"Important milestones\"],\n",
        "        \"deliverables\": [\"Expected deliverables\"]\n",
        "    }},\n",
        "    \"project_phases\": {{\n",
        "        \"suggested_phases\": [\"Recommended development phases\"],\n",
        "        \"phase_descriptions\": [\"Description of each phase\"]\n",
        "    }},\n",
        "    \"evaluation_criteria\": {{\n",
        "        \"technical_criteria\": [\"Technical evaluation factors\"],\n",
        "        \"commercial_criteria\": [\"Cost evaluation factors\"],\n",
        "        \"experience_criteria\": [\"Experience requirements\"],\n",
        "        \"weightage\": \"Scoring weightage if mentioned\"\n",
        "    }},\n",
        "    \"submission_requirements\": {{\n",
        "        \"proposal_format\": \"Required proposal format\",\n",
        "        \"submission_deadline\": \"Deadline for submission\",\n",
        "        \"required_documents\": [\"Required documents\"],\n",
        "        \"contact_information\": \"Contact details\"\n",
        "    }},\n",
        "    \"risk_analysis\": {{\n",
        "        \"technical_risks\": [\"Potential technical challenges\"],\n",
        "        \"project_risks\": [\"Project delivery risks\"],\n",
        "        \"mitigation_strategies\": [\"Suggested risk mitigation\"]\n",
        "    }},\n",
        "    \"competitive_analysis\": {{\n",
        "        \"likely_competitors\": [\"Potential competing companies\"],\n",
        "        \"competitive_advantages\": [\"Areas to highlight\"],\n",
        "        \"differentiators\": [\"Unique selling points to emphasize\"]\n",
        "    }},\n",
        "    \"bid_strategy\": {{\n",
        "        \"key_strengths_to_highlight\": [\"Strengths to emphasize\"],\n",
        "        \"pricing_strategy\": \"Recommended pricing approach\",\n",
        "        \"proposal_focus_areas\": [\"Areas to focus on in proposal\"],\n",
        "        \"win_probability\": \"Estimated win probability and reasoning\"\n",
        "    }}\n",
        "}}\n",
        "\n",
        "RFP Document:\n",
        "{text}\n",
        "\n",
        "Provide only the JSON response with detailed analysis. Be thorough and extract as much relevant information as possible.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                analysis_prompt,\n",
        "                generation_config=self.generation_config\n",
        "            )\n",
        "\n",
        "            # Clean and parse JSON response\n",
        "            content = response.text.strip()\n",
        "\n",
        "            # Remove markdown code blocks if present\n",
        "            if content.startswith('```json'):\n",
        "                content = content[7:]\n",
        "            if content.endswith('```'):\n",
        "                content = content[:-3]\n",
        "\n",
        "            # Clean any remaining markdown\n",
        "            content = content.strip()\n",
        "\n",
        "            analysis = json.loads(content)\n",
        "            return analysis\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            st.error(f\"Error parsing AI response: {str(e)}\")\n",
        "            # Try to extract JSON from the response if it's embedded\n",
        "            try:\n",
        "                # Look for JSON pattern in the response\n",
        "                json_match = re.search(r'\\{.*\\}', response.text, re.DOTALL)\n",
        "                if json_match:\n",
        "                    analysis = json.loads(json_match.group())\n",
        "                    return analysis\n",
        "            except:\n",
        "                pass\n",
        "            return {\"error\": \"Failed to parse analysis\"}\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error analyzing RFP: {str(e)}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def generate_executive_summary(self, analysis: Dict[str, Any]) -> str:\n",
        "        \"\"\"Generate an executive summary of the RFP analysis\"\"\"\n",
        "\n",
        "        summary_prompt = f\"\"\"You are an expert business analyst. Create a concise executive summary for contractors.\n",
        "\n",
        "Based on this RFP analysis, create a brief executive summary (200-300 words) that highlights:\n",
        "1. Key project opportunity\n",
        "2. Critical requirements\n",
        "3. Main challenges and risks\n",
        "4. Recommended bid approach\n",
        "5. Win probability assessment\n",
        "\n",
        "Analysis data:\n",
        "{json.dumps(analysis, indent=2)}\n",
        "\n",
        "Write in a professional, actionable tone for decision-makers.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                summary_prompt,\n",
        "                generation_config=self.generation_config\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            return f\"Error generating summary: {str(e)}\"\n",
        "\n",
        "    def generate_docx_report(self, analysis: Dict[str, Any], summary: str) -> BytesIO:\n",
        "        \"\"\"Generate a comprehensive DOCX report\"\"\"\n",
        "        try:\n",
        "            # Create a new Document\n",
        "            doc = Document()\n",
        "\n",
        "            # Add title\n",
        "            title = doc.add_heading('RFP Analysis Report', 0)\n",
        "            title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "\n",
        "            # Add timestamp\n",
        "            doc.add_paragraph(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            doc.add_paragraph(\"\")\n",
        "\n",
        "            # Executive Summary\n",
        "            doc.add_heading('Executive Summary', level=1)\n",
        "            doc.add_paragraph(summary)\n",
        "            doc.add_page_break()\n",
        "\n",
        "            # Project Overview\n",
        "            if 'project_overview' in analysis:\n",
        "                doc.add_heading('Project Overview', level=1)\n",
        "                overview = analysis['project_overview']\n",
        "\n",
        "                table = doc.add_table(rows=1, cols=2)\n",
        "                table.style = 'Table Grid'\n",
        "                hdr_cells = table.rows[0].cells\n",
        "                hdr_cells[0].text = 'Attribute'\n",
        "                hdr_cells[1].text = 'Details'\n",
        "\n",
        "                for key, value in overview.items():\n",
        "                    row_cells = table.add_row().cells\n",
        "                    row_cells[0].text = key.replace('_', ' ').title()\n",
        "                    row_cells[1].text = str(value) if value else 'N/A'\n",
        "\n",
        "                doc.add_paragraph(\"\")\n",
        "\n",
        "            # Requirements\n",
        "            if 'requirements' in analysis:\n",
        "                doc.add_heading('Requirements', level=1)\n",
        "                requirements = analysis['requirements']\n",
        "\n",
        "                for req_type, req_list in requirements.items():\n",
        "                    if req_list:\n",
        "                        doc.add_heading(req_type.replace('_', ' ').title(), level=2)\n",
        "                        for req in req_list:\n",
        "                            doc.add_paragraph(f\"• {req}\")\n",
        "                        doc.add_paragraph(\"\")\n",
        "\n",
        "            # Technology Stack\n",
        "            if 'technology_stack' in analysis:\n",
        "                doc.add_heading('Technology Stack', level=1)\n",
        "                tech_stack = analysis['technology_stack']\n",
        "\n",
        "                for tech_type, tech_list in tech_stack.items():\n",
        "                    if tech_list:\n",
        "                        doc.add_heading(tech_type.replace('_', ' ').title(), level=2)\n",
        "                        for tech in tech_list:\n",
        "                            doc.add_paragraph(f\"• {tech}\")\n",
        "                        doc.add_paragraph(\"\")\n",
        "\n",
        "            # Project Details\n",
        "            if 'project_details' in analysis:\n",
        "                doc.add_heading('Project Details', level=1)\n",
        "                details = analysis['project_details']\n",
        "\n",
        "                table = doc.add_table(rows=1, cols=2)\n",
        "                table.style = 'Table Grid'\n",
        "                hdr_cells = table.rows[0].cells\n",
        "                hdr_cells[0].text = 'Attribute'\n",
        "                hdr_cells[1].text = 'Details'\n",
        "\n",
        "                for key, value in details.items():\n",
        "                    if key == 'key_milestones' or key == 'deliverables':\n",
        "                        if value:\n",
        "                            row_cells = table.add_row().cells\n",
        "                            row_cells[0].text = key.replace('_', ' ').title()\n",
        "                            row_cells[1].text = '\\n'.join([f\"• {item}\" for item in value])\n",
        "                    else:\n",
        "                        row_cells = table.add_row().cells\n",
        "                        row_cells[0].text = key.replace('_', ' ').title()\n",
        "                        row_cells[1].text = str(value) if value else 'N/A'\n",
        "\n",
        "                doc.add_paragraph(\"\")\n",
        "\n",
        "            # Bid Strategy\n",
        "            if 'bid_strategy' in analysis:\n",
        "                doc.add_heading('Bid Strategy Recommendations', level=1)\n",
        "                strategy = analysis['bid_strategy']\n",
        "\n",
        "                for key, value in strategy.items():\n",
        "                    if value:\n",
        "                        doc.add_heading(key.replace('_', ' ').title(), level=2)\n",
        "                        if isinstance(value, list):\n",
        "                            for item in value:\n",
        "                                doc.add_paragraph(f\"• {item}\")\n",
        "                        else:\n",
        "                            doc.add_paragraph(str(value))\n",
        "                        doc.add_paragraph(\"\")\n",
        "\n",
        "            # Risk Analysis\n",
        "            if 'risk_analysis' in analysis:\n",
        "                doc.add_heading('Risk Analysis', level=1)\n",
        "                risks = analysis['risk_analysis']\n",
        "\n",
        "                for risk_type, risk_list in risks.items():\n",
        "                    if risk_list:\n",
        "                        doc.add_heading(risk_type.replace('_', ' ').title(), level=2)\n",
        "                        if isinstance(risk_list, list):\n",
        "                            for risk in risk_list:\n",
        "                                doc.add_paragraph(f\"• {risk}\")\n",
        "                        else:\n",
        "                            doc.add_paragraph(str(risk_list))\n",
        "                        doc.add_paragraph(\"\")\n",
        "\n",
        "            # Submission Requirements\n",
        "            if 'submission_requirements' in analysis:\n",
        "                doc.add_heading('Submission Requirements', level=1)\n",
        "                submission = analysis['submission_requirements']\n",
        "\n",
        "                table = doc.add_table(rows=1, cols=2)\n",
        "                table.style = 'Table Grid'\n",
        "                hdr_cells = table.rows[0].cells\n",
        "                hdr_cells[0].text = 'Requirement'\n",
        "                hdr_cells[1].text = 'Details'\n",
        "\n",
        "                for key, value in submission.items():\n",
        "                    if key == 'required_documents' and value:\n",
        "                        row_cells = table.add_row().cells\n",
        "                        row_cells[0].text = key.replace('_', ' ').title()\n",
        "                        row_cells[1].text = '\\n'.join([f\"• {doc}\" for doc in value])\n",
        "                    else:\n",
        "                        row_cells = table.add_row().cells\n",
        "                        row_cells[0].text = key.replace('_', ' ').title()\n",
        "                        row_cells[1].text = str(value) if value else 'N/A'\n",
        "\n",
        "            # Save to BytesIO\n",
        "            docx_buffer = BytesIO()\n",
        "            doc.save(docx_buffer)\n",
        "            docx_buffer.seek(0)\n",
        "\n",
        "            return docx_buffer\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error generating DOCX report: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"RFP Analyzer AI Agent\",\n",
        "        page_icon=\"📄\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🤖 RFP Analysis AI Agent\")\n",
        "    st.markdown(\"*Intelligent RFP analysis for contractor companies*\")\n",
        "\n",
        "    # Sidebar for configuration\n",
        "    with st.sidebar:\n",
        "        st.header(\"Configuration\")\n",
        "        api_key = st.text_input(\"Google Gemini API Key\", type=\"password\",\n",
        "                               help=\"Enter your Google Gemini API key\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"**Supported Formats:**\")\n",
        "        st.markdown(\"• PDF documents\")\n",
        "        st.markdown(\"• Images (PNG, JPG, JPEG)\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"**AI Model:**\")\n",
        "        st.markdown(\"• Gemini 2.0 Flash\")\n",
        "\n",
        "        if st.button(\"Clear Analysis\", type=\"secondary\"):\n",
        "            if \"analysis_result\" in st.session_state:\n",
        "                del st.session_state.analysis_result\n",
        "            if \"extracted_text\" in st.session_state:\n",
        "                del st.session_state.extracted_text\n",
        "            if \"executive_summary\" in st.session_state:\n",
        "                del st.session_state.executive_summary\n",
        "            st.rerun()\n",
        "\n",
        "    if not api_key:\n",
        "        st.warning(\"Please enter your Google Gemini API key in the sidebar to proceed.\")\n",
        "        st.info(\"You can get your Gemini API key from: https://makersuite.google.com/app/apikey\")\n",
        "        return\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = RFPAnalyzer(api_key)\n",
        "\n",
        "    # File upload section\n",
        "    st.header(\"📤 Upload RFP Document\")\n",
        "    uploaded_file = st.file_uploader(\n",
        "        \"Choose an RFP document\",\n",
        "        type=['pdf', 'png', 'jpg', 'jpeg'],\n",
        "        help=\"Upload a PDF or image file containing the RFP\"\n",
        "    )\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Display file info\n",
        "        st.success(f\"File uploaded: {uploaded_file.name} ({uploaded_file.size} bytes)\")\n",
        "\n",
        "        # Extract text\n",
        "        if st.button(\"🔍 Analyze RFP\", type=\"primary\"):\n",
        "            with st.spinner(\"Extracting text from document...\"):\n",
        "                if uploaded_file.type == \"application/pdf\":\n",
        "                    extracted_text = analyzer.extract_text_from_pdf(uploaded_file)\n",
        "                else:\n",
        "                    extracted_text = analyzer.extract_text_from_image(uploaded_file)\n",
        "\n",
        "                st.session_state.extracted_text = extracted_text\n",
        "\n",
        "            if extracted_text:\n",
        "                with st.spinner(\"Analyzing RFP with AI... This may take a few minutes.\"):\n",
        "                    analysis = analyzer.analyze_rfp(extracted_text)\n",
        "                    st.session_state.analysis_result = analysis\n",
        "\n",
        "                st.success(\"✅ Analysis completed!\")\n",
        "\n",
        "    # Display results\n",
        "    if \"analysis_result\" in st.session_state and \"extracted_text\" in st.session_state:\n",
        "        analysis = st.session_state.analysis_result\n",
        "\n",
        "        if \"error\" not in analysis:\n",
        "            # Executive Summary\n",
        "            st.header(\"📋 Executive Summary\")\n",
        "            with st.spinner(\"Generating executive summary...\"):\n",
        "                if \"executive_summary\" not in st.session_state:\n",
        "                    summary = analyzer.generate_executive_summary(analysis)\n",
        "                    st.session_state.executive_summary = summary\n",
        "                else:\n",
        "                    summary = st.session_state.executive_summary\n",
        "\n",
        "                st.markdown(summary)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Detailed Analysis Tabs\n",
        "            tab1, tab2, tab3, tab4, tab5 = st.tabs([\n",
        "                \"📊 Project Overview\",\n",
        "                \"⚙️ Technical Details\",\n",
        "                \"💼 Business Details\",\n",
        "                \"🎯 Bid Strategy\",\n",
        "                \"📄 Raw Text\"\n",
        "            ])\n",
        "\n",
        "            with tab1:\n",
        "                st.subheader(\"Project Overview\")\n",
        "                if \"project_overview\" in analysis:\n",
        "                    overview = analysis[\"project_overview\"]\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        st.write(f\"**Title:** {overview.get('title', 'N/A')}\")\n",
        "                        st.write(f\"**Client:** {overview.get('client_organization', 'N/A')}\")\n",
        "                        st.write(f\"**Type:** {overview.get('project_type', 'N/A')}\")\n",
        "\n",
        "                    with col2:\n",
        "                        st.write(f\"**Industry:** {overview.get('industry_sector', 'N/A')}\")\n",
        "                        st.write(f\"**Description:** {overview.get('description', 'N/A')}\")\n",
        "\n",
        "                st.subheader(\"Requirements\")\n",
        "                if \"requirements\" in analysis:\n",
        "                    req = analysis[\"requirements\"]\n",
        "\n",
        "                    if req.get(\"functional_requirements\"):\n",
        "                        st.write(\"**Functional Requirements:**\")\n",
        "                        for item in req[\"functional_requirements\"]:\n",
        "                            st.write(f\"• {item}\")\n",
        "\n",
        "                    if req.get(\"technical_requirements\"):\n",
        "                        st.write(\"**Technical Requirements:**\")\n",
        "                        for item in req[\"technical_requirements\"]:\n",
        "                            st.write(f\"• {item}\")\n",
        "\n",
        "            with tab2:\n",
        "                st.subheader(\"Technology Stack\")\n",
        "                if \"technology_stack\" in analysis:\n",
        "                    tech = analysis[\"technology_stack\"]\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        if tech.get(\"preferred_technologies\"):\n",
        "                            st.write(\"**Preferred Technologies:**\")\n",
        "                            for item in tech[\"preferred_technologies\"]:\n",
        "                                st.write(f\"• {item}\")\n",
        "\n",
        "                        if tech.get(\"platforms\"):\n",
        "                            st.write(\"**Platforms:**\")\n",
        "                            for item in tech[\"platforms\"]:\n",
        "                                st.write(f\"• {item}\")\n",
        "\n",
        "                    with col2:\n",
        "                        if tech.get(\"databases\"):\n",
        "                            st.write(\"**Databases:**\")\n",
        "                            for item in tech[\"databases\"]:\n",
        "                                st.write(f\"• {item}\")\n",
        "\n",
        "                        if tech.get(\"third_party_integrations\"):\n",
        "                            st.write(\"**Integrations:**\")\n",
        "                            for item in tech[\"third_party_integrations\"]:\n",
        "                                st.write(f\"• {item}\")\n",
        "\n",
        "                st.subheader(\"Project Phases\")\n",
        "                if \"project_phases\" in analysis:\n",
        "                    phases = analysis[\"project_phases\"]\n",
        "                    if phases.get(\"suggested_phases\"):\n",
        "                        for i, phase in enumerate(phases[\"suggested_phases\"], 1):\n",
        "                            st.write(f\"**Phase {i}:** {phase}\")\n",
        "\n",
        "            with tab3:\n",
        "                st.subheader(\"Project Details\")\n",
        "                if \"project_details\" in analysis:\n",
        "                    details = analysis[\"project_details\"]\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        st.write(f\"**Budget:** {details.get('estimated_budget', 'N/A')}\")\n",
        "                        st.write(f\"**Timeline:** {details.get('timeline', 'N/A')}\")\n",
        "                        st.write(f\"**Start Date:** {details.get('start_date', 'N/A')}\")\n",
        "\n",
        "                    with col2:\n",
        "                        if details.get(\"key_milestones\"):\n",
        "                            st.write(\"**Key Milestones:**\")\n",
        "                            for milestone in details[\"key_milestones\"]:\n",
        "                                st.write(f\"• {milestone}\")\n",
        "\n",
        "                st.subheader(\"Submission Requirements\")\n",
        "                if \"submission_requirements\" in analysis:\n",
        "                    sub = analysis[\"submission_requirements\"]\n",
        "                    st.write(f\"**Deadline:** {sub.get('submission_deadline', 'N/A')}\")\n",
        "                    st.write(f\"**Contact:** {sub.get('contact_information', 'N/A')}\")\n",
        "\n",
        "                    if sub.get(\"required_documents\"):\n",
        "                        st.write(\"**Required Documents:**\")\n",
        "                        for doc in sub[\"required_documents\"]:\n",
        "                            st.write(f\"• {doc}\")\n",
        "\n",
        "            with tab4:\n",
        "                st.subheader(\"Bid Strategy Recommendations\")\n",
        "                if \"bid_strategy\" in analysis:\n",
        "                    strategy = analysis[\"bid_strategy\"]\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        if strategy.get(\"key_strengths_to_highlight\"):\n",
        "                            st.write(\"**Strengths to Highlight:**\")\n",
        "                            for strength in strategy[\"key_strengths_to_highlight\"]:\n",
        "                                st.write(f\"• {strength}\")\n",
        "\n",
        "                        st.write(f\"**Pricing Strategy:** {strategy.get('pricing_strategy', 'N/A')}\")\n",
        "\n",
        "                    with col2:\n",
        "                        if strategy.get(\"proposal_focus_areas\"):\n",
        "                            st.write(\"**Proposal Focus Areas:**\")\n",
        "                            for area in strategy[\"proposal_focus_areas\"]:\n",
        "                                st.write(f\"• {area}\")\n",
        "\n",
        "                        st.write(f\"**Win Probability:** {strategy.get('win_probability', 'N/A')}\")\n",
        "\n",
        "                st.subheader(\"Risk Analysis\")\n",
        "                if \"risk_analysis\" in analysis:\n",
        "                    risks = analysis[\"risk_analysis\"]\n",
        "\n",
        "                    if risks.get(\"technical_risks\"):\n",
        "                        st.write(\"**Technical Risks:**\")\n",
        "                        for risk in risks[\"technical_risks\"]:\n",
        "                            st.write(f\"• {risk}\")\n",
        "\n",
        "                    if risks.get(\"mitigation_strategies\"):\n",
        "                        st.write(\"**Mitigation Strategies:**\")\n",
        "                        for strategy in risks[\"mitigation_strategies\"]:\n",
        "                            st.write(f\"• {strategy}\")\n",
        "\n",
        "            with tab5:\n",
        "                st.subheader(\"Extracted Text\")\n",
        "                st.text_area(\"Raw extracted text:\",\n",
        "                           value=st.session_state.extracted_text,\n",
        "                           height=400,\n",
        "                           disabled=True)\n",
        "\n",
        "                # Download options\n",
        "                st.subheader(\"Download Results\")\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                with col1:\n",
        "                    # Download JSON analysis\n",
        "                    json_str = json.dumps(analysis, indent=2)\n",
        "                    st.download_button(\n",
        "                        label=\"📥 Download Analysis (JSON)\",\n",
        "                        data=json_str,\n",
        "                        file_name=f\"rfp_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "                        mime=\"application/json\"\n",
        "                    )\n",
        "\n",
        "                with col2:\n",
        "                    # Download extracted text\n",
        "                    st.download_button(\n",
        "                        label=\"📥 Download Extracted Text\",\n",
        "                        data=st.session_state.extracted_text,\n",
        "                        file_name=f\"extracted_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\",\n",
        "                        mime=\"text/plain\"\n",
        "                    )\n",
        "\n",
        "                with col3:\n",
        "                    # Download DOCX report\n",
        "                    if st.button(\"📥 Generate DOCX Report\"):\n",
        "                        with st.spinner(\"Generating DOCX report...\"):\n",
        "                            docx_buffer = analyzer.generate_docx_report(analysis, st.session_state.executive_summary)\n",
        "                            if docx_buffer:\n",
        "                                st.download_button(\n",
        "                                    label=\"📥 Download DOCX Report\",\n",
        "                                    data=docx_buffer.getvalue(),\n",
        "                                    file_name=f\"rfp_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx\",\n",
        "                                    mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "                                )\n",
        "                            else:\n",
        "                                st.error(\"Failed to generate DOCX report\")\n",
        "\n",
        "        else:\n",
        "            st.error(f\"Analysis failed: {analysis.get('error', 'Unknown error')}\")\n",
        "\n",
        "    # Footer\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"*Built with Google Gemini • Made for Contractor Companies*\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeyQX0wP3Yvi",
        "outputId": "a66ba895-108c-40ea-b60b-cdd1f063c686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit google-generativeai pytesseract pillow pdf2image PyMuPDF pyngrok python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgFVylUo3T72",
        "outputId": "562635c4-f977-454a-8305-d8ab97e60952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Your RFP Analyzer is running at: NgrokTunnel: \"https://d781-34-16-229-151.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "Click the link above to access your application!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"rfp_analyzer.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "# Start Streamlit in background\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "time.sleep(10)\n",
        "\n",
        "# Create public URL\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🚀 Your RFP Analyzer is running at: {public_url}\")\n",
        "print(\"Click the link above to access your application!\")\n",
        "\n",
        "# Keep the cell running\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping the application...\")\n",
        "    ngrok.disconnect(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma8hG5bR4Fie",
        "outputId": "f6a43382-5149-4851-a966-de432dcfc1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"meetdesai2017@gmail.com\"\n",
        "!git config --global user.name \"MeetDesai21\"\n",
        "\n",
        "!git clone https://github.com/MeetDesai21/RFP-Analysis-Agent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_2szaB14GKk",
        "outputId": "9848ce4b-5182-44b9-ffef-23c3a6ca6f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RFP-Analysis-Agent'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp RFP_AGENT_BEST_ONE_RIGHT_NOW.ipynb RFP-Analysis-Agent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUy64bSu4QNt",
        "outputId": "b056c6cc-858a-4afd-9a2b-080ae97fa4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'RFP_AGENT_BEST_ONE_RIGHT_NOW.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJOtwZ1x4Se0",
        "outputId": "7d56ca4d-9113-4877-8ff6-8ff18687b0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  RFP-Analysis-Agent  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaYFMTt74lbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6bDJefOppih7kbYdJqURM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}